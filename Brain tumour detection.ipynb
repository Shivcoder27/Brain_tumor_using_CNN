{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88423d99-75b2-4086-bdd6-e75473e2cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0248b388-bbf2-42e9-b618-2bb6f85b0f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyterlab in d:\\annaconda package\\lib\\site-packages (4.0.11)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000020AD3A50710>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /simple/tensorflow-gpu/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000020AD3FE7690>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /simple/tensorflow-gpu/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000020AD3FDFD10>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /simple/tensorflow-gpu/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000020AD3FE1850>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /simple/tensorflow-gpu/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000020AD3FE2B50>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /simple/tensorflow-gpu/\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [44 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"D:\\Annaconda package\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\requirements.py\", line 35, in __init__\n",
      "      parsed = _parse_requirement(requirement_string)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"D:\\Annaconda package\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 64, in parse_requirement\n",
      "      return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"D:\\Annaconda package\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 82, in _parse_requirement\n",
      "      url, specifier, marker = _parse_requirement_details(tokenizer)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"D:\\Annaconda package\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 126, in _parse_requirement_details\n",
      "      marker = _parse_requirement_marker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"D:\\Annaconda package\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 147, in _parse_requirement_marker\n",
      "      tokenizer.raise_syntax_error(\n",
      "    File \"D:\\Annaconda package\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_tokenizer.py\", line 165, in raise_syntax_error\n",
      "      raise ParserSyntaxError(\n",
      "  setuptools.extern.packaging._tokenizer.ParserSyntaxError: Expected end or semicolon (after name and no valid version specifier)\n",
      "      python_version>\"3.7\"\n",
      "                    ^\n",
      "  \n",
      "  The above exception was the direct cause of the following exception:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Windows\\Temp\\pip-install-pmx6v0vf\\tensorflow-gpu_64d354e6fd3148098d050f09c951dffc\\setup.py\", line 40, in <module>\n",
      "      setuptools.setup()\n",
      "    File \"D:\\Annaconda package\\Lib\\site-packages\\setuptools\\__init__.py\", line 102, in setup\n",
      "      _install_setup_requires(attrs)\n",
      "    File \"D:\\Annaconda package\\Lib\\site-packages\\setuptools\\__init__.py\", line 73, in _install_setup_requires\n",
      "      dist.parse_config_files(ignore_option_errors=True)\n",
      "    File \"D:\\Annaconda package\\Lib\\site-packages\\setuptools\\dist.py\", line 655, in parse_config_files\n",
      "      self._finalize_requires()\n",
      "    File \"D:\\Annaconda package\\Lib\\site-packages\\setuptools\\dist.py\", line 390, in _finalize_requires\n",
      "      self._normalize_requires()\n",
      "    File \"D:\\Annaconda package\\Lib\\site-packages\\setuptools\\dist.py\", line 405, in _normalize_requires\n",
      "      self.install_requires = list(map(str, _reqs.parse(install_requires)))\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"D:\\Annaconda package\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\requirements.py\", line 37, in __init__\n",
      "      raise InvalidRequirement(str(e)) from e\n",
      "  setuptools.extern.packaging.requirements.InvalidRequirement: Expected end or semicolon (after name and no valid version specifier)\n",
      "      python_version>\"3.7\"\n",
      "                    ^\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting tensorflow-gpu\n",
      "  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "pip install jupyterlab tensorflow-gpu torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "388df893-8f49-422a-af6e-e9a1586e7d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('testing', 2), ('train', 2), ('val', 2)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_DIR = \"D:\\\\PYTHON\\\\PYTHON PROJECTS\\\\pythonDEEP3.11.7\\\\brain tumor\\\\archive\\\\Brain Tumor Data Set\\\\Brain Tumor Data Set\"\n",
    "num_of_img = {}\n",
    "\n",
    "# Loop through each subdirectory in the root directory\n",
    "for dir in os.listdir(ROOT_DIR):\n",
    "    dir_path = os.path.join(ROOT_DIR, dir)\n",
    "    if os.path.isdir(dir_path):  # Check if it is a directory\n",
    "        num_of_img[dir] = len(os.listdir(dir_path))  # Count the number of files\n",
    "\n",
    "# Print the number of images in each s\n",
    "num_of_img.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fc9b57f-9b28-4da6-bca3-cf60c3bf88f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('testing', 2), ('train', 2), ('val', 2)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dir in os.listdir(ROOT_DIR):\n",
    "    dir_path = os.path.join(ROOT_DIR, dir)\n",
    "    if os.path.isdir(dir_path):  # Check if it is a directory\n",
    "        num_of_img[dir] = len(os.listdir(dir_path))  # Count the number of files\n",
    "\n",
    "# Print the number of images in each s\n",
    "num_of_img.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db9ab13-20ed-48cf-b203-02613c942963",
   "metadata": {},
   "source": [
    "# SPLIT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e269816-72c9-4ca7-aacc-75fce000fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% Train data\n",
    "# 15% for validation\n",
    "# 15% for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23251637-d239-45bf-8d12-39187b432372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will create training folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cec82b4-1790-4d62-9cd6-976bab894804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataFolder(p, split):\n",
    "    target_dir = os.path.join(ROOT_DIR, p)\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.mkdir(target_dir)\n",
    "        print(f\"Created {p} folder.\")\n",
    "        \n",
    "        for dir in os.listdir(ROOT_DIR):\n",
    "            class_path = os.path.join(ROOT_DIR, dir)\n",
    "\n",
    "            # Ensure it is a directory (skip files)\n",
    "            if os.path.isdir(class_path):\n",
    "                # Create a corresponding class folder in the target directory\n",
    "                target_class_dir = os.path.join(target_dir, dir)\n",
    "                os.makedirs(target_class_dir, exist_ok=True)\n",
    "                \n",
    "                # Randomly select images to move\n",
    "                images = os.listdir(class_path)\n",
    "                num_images_to_move = math.floor(split * len(images))  # Number of images to move\n",
    "                selected_images = np.random.choice(images, size=num_images_to_move, replace=False)\n",
    "\n",
    "                # Move images\n",
    "                for img in selected_images:\n",
    "                    src = os.path.join(class_path, img)\n",
    "                    dest = os.path.join(target_class_dir, img)\n",
    "                    \n",
    "                    try:\n",
    "                        shutil.copy(src, dest)  # Copy the image to the target directory\n",
    "                        os.remove(src)          # Remove the original file\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {src}: {e}\")\n",
    "    else:\n",
    "        print(f\"{p} folder already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14de632b-1c13-4048-ab21-d89c96a5023a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train folder already exists.\n"
     ]
    }
   ],
   "source": [
    "dataFolder(\"train\",0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f5742ab-6ef2-42f2-93e1-0dd6d3a9e246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val folder already exists.\n"
     ]
    }
   ],
   "source": [
    "dataFolder(\"val\",0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f1ca53d-8f18-42d9-972c-7aa0090baea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing folder already exists.\n"
     ]
    }
   ],
   "source": [
    "dataFolder(\"testing\",0.15)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e514055-2977-4e10-b714-09e9106af256",
   "metadata": {},
   "source": [
    "# MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d64178d7-822e-40be-b5e7-2e7c2f1ec29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D,MaxPool2D,Dropout,Flatten,Dense,BatchNormalization,GlobalAvgPool2D\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "177f92b0-1384-407a-8c25-ad75464ed3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Annaconda package\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,220</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,800</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,537,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m448\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m220\u001b[0m, \u001b[38;5;34m220\u001b[0m, \u001b[38;5;34m36\u001b[0m)        │           \u001b[38;5;34m5,220\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m36\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m108\u001b[0m, \u001b[38;5;34m108\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m20,800\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │       \u001b[38;5;34m5,537,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,638,245</span> (21.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,638,245\u001b[0m (21.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,638,245</span> (21.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,638,245\u001b[0m (21.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Convolutional Layers\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "\n",
    "model.add(Conv2D(filters=36, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Dropout Layer\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "# Flatten Layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully Connected Layers\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0145f6-79f4-4979-b12d-dda61d88dff3",
   "metadata": {},
   "source": [
    "# Preparing our Data using Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7853dbc-b670-4f8b-a2b9-7801aa8ce251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingImages(path):\n",
    "    \"\"\"\n",
    "    input: path\n",
    "    output: pre processed imgaes\n",
    "    \"\"\"\n",
    "    image_data = ImageDataGenerator(zoom_range=0.2,shear_range=0.2,rescale=1/255,horizontal_flip =True)\n",
    "    image= image_data.flow_from_directory(directory = path,target_size=(224,224),batch_size = 32,class_mode='binary') \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0791c0b7-d2d0-4134-8a91-270a21dc4e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3219 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "path = \"D:\\\\PYTHON\\PYTHON PROJECTS\\\\pythonDEEP3.11.7\\\\brain tumor\\\\archive\\\\Brain Tumor Data Set\\\\Brain Tumor Data Set\\\\train\"\n",
    "train_data = preprocessingImages(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c3d4908-1919-49dc-b351-26f6957e722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingImages2(path):\n",
    "    \"\"\"\n",
    "    input: path\n",
    "    output: pre processed imgaes\n",
    "    \"\"\"\n",
    "    image_data = ImageDataGenerator(rescale=1/255)\n",
    "    image= image_data.flow_from_directory(directory = path,target_size=(224,224),batch_size = 32,class_mode='binary') \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86a47891-f6c2-4cb5-a1a6-d83d7b4171de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 999 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "path = \"D:\\\\PYTHON\\PYTHON PROJECTS\\\\pythonDEEP3.11.7\\\\brain tumor\\\\archive\\\\Brain Tumor Data Set\\\\Brain Tumor Data Set\\\\testing\"\n",
    "test_data = preprocessingImages2(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b4dced4-93e0-4131-817a-84fb72fe02c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 207 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "path = \"D:\\\\PYTHON\\PYTHON PROJECTS\\\\pythonDEEP3.11.7\\\\brain tumor\\\\archive\\\\Brain Tumor Data Set\\\\Brain Tumor Data Set\\\\val\"\n",
    "val_data = preprocessingImages2(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3652a85-3dfc-4d7b-a2a0-4b7ba5dcf6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping and model check point\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# EarlyStopping callback\n",
    "es = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",   # Metric to monitor\n",
    "    min_delta=0.01,           # Minimum change to qualify as an improvement\n",
    "    patience=3,               # Number of epochs with no improvement before stopping\n",
    "    verbose=1,                # Verbosity mode (1 = output logs)\n",
    "    mode='auto'               # Direction of the monitored metric (max for accuracy)\n",
    ")\n",
    "\n",
    "# ModelCheckpoint callback\n",
    "mc = ModelCheckpoint(\n",
    "    filepath=\"D:\\\\PYTHON\\PYTHON PROJECTS\\\\pythonDEEP3.11.7\\\\brain tumor\\\\bestmodel.keras\",  # Path to save the model\n",
    "    monitor=\"val_accuracy\",     # Metric to monitor\n",
    "    verbose=1,                  # Verbosity mode\n",
    "    save_best_only=True,        # Save only when the monitored metric improves\n",
    "    mode='auto'                 # Direction of the monitored metric (max for accuracy)\n",
    ")\n",
    "\n",
    "# Combine callbacks\n",
    "cd = [es, mc]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f8d931-4d97-47dc-bab8-a8684a6edfc4",
   "metadata": {},
   "source": [
    "# Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dafb099a-4069-4fc9-a08a-0b905990f5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Annaconda package\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4434 - loss: 1.0461"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Annaconda package\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.69082, saving model to D:\\PYTHON\\PYTHON PROJECTS\\pythonDEEP3.11.7\\brain tumor\\bestmodel.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Annaconda package\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.4471 - loss: 1.0303 - val_accuracy: 0.6908 - val_loss: 0.6830\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4945 - loss: 0.6930\n",
      "Epoch 2: val_accuracy did not improve from 0.69082\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.4981 - loss: 0.6930 - val_accuracy: 0.5507 - val_loss: 0.6758\n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5405 - loss: 0.6913\n",
      "Epoch 3: val_accuracy did not improve from 0.69082\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5386 - loss: 0.6914 - val_accuracy: 0.6763 - val_loss: 0.6700\n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5669 - loss: 0.6821\n",
      "Epoch 4: val_accuracy did not improve from 0.69082\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.5643 - loss: 0.6820 - val_accuracy: 0.6570 - val_loss: 0.6177\n",
      "Epoch 4: early stopping\n"
     ]
    }
   ],
   "source": [
    "hs = model.fit(\n",
    "    x=train_data,\n",
    "    steps_per_epoch=8,\n",
    "    epochs=10,  # Add the number of epochs (if not already set)\n",
    "    verbose=1,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=16,\n",
    "    callbacks=cd\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e029f2d-f596-4028-8e82-b0f23cf7cf83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
